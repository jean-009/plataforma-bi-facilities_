{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9644617-0918-4d31-93ec-d26ab57522d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ETL para o arquivo: 2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv\n",
      "--- FASE 1: EXTRAÇÃO (READ) ---\n",
      "❌ ERRO NA LEITURA: [Errno 2] No such file or directory: '..\\\\01_raw_data\\\\2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\01_raw_data\\\\2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- FASE 1: EXTRAÇÃO (READ) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Lendo o CSV. Como é CSV, precisamos do separador (',')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCAMINHO_BRUTO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLINHA_CABECALHO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Arquivo lido com sucesso. Dimensões brutas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\01_raw_data\\\\2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np # Importamos numpy para usar NaN\n",
    "\n",
    "# --- FASE 1 & 2: EXTRAÇÃO E TRANSFORMAÇÃO (E & T) ---\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# TODO: NOME EXATO DA PLANILHA (Usando a folha 'BASE' que é a mais limpa)\n",
    "NOME_ARQUIVO = '2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv'\n",
    "LINHA_CABECALHO = 0 # O cabeçalho parece estar na primeira linha (índice 0)\n",
    "\n",
    "# Mapeamento: os nomes REAIS para os nomes do banco\n",
    "COLUNAS_PARA_MANTER = {\n",
    "    'DATA': 'data_movimentacao',\n",
    "    'MES': 'mes',\n",
    "    'EMPRESA': 'unidade_negocio_nome',\n",
    "    'FORNECEDOR': 'contraparte_nome',\n",
    "    'VALOR': 'valor',\n",
    "    'TIPO': 'tipo_transacao',\n",
    "    'CENTRO DE CUSTO': 'centro_custo'\n",
    "}\n",
    "\n",
    "CAMINHO_BRUTO = Path('../01_raw_data') / NOME_ARQUIVO\n",
    "\n",
    "print(f\"Iniciando ETL para o arquivo: {NOME_ARQUIVO}\")\n",
    "print(\"--- FASE 1: EXTRAÇÃO (READ) ---\")\n",
    "\n",
    "try:\n",
    "    # Lendo o CSV. Como é CSV, precisamos do separador (',')\n",
    "    df = pd.read_csv(CAMINHO_BRUTO, header=LINHA_CABECALHO, sep=',')\n",
    "    print(f\"✅ Arquivo lido com sucesso. Dimensões brutas: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA LEITURA: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\")\n",
    "\n",
    "# 1. Renomeação, Seleção e Limpeza Básica\n",
    "df_limpo = df.rename(columns=COLUNAS_PARA_MANTER)\n",
    "colunas_finais_mapeadas = list(COLUNAS_PARA_MANTER.values())\n",
    "\n",
    "# Remove a coluna de lixo que pode ter vindo do final do CSV\n",
    "if df_limpo.columns[-1] == 'Unnamed: 7':\n",
    "    df_limpo = df_limpo.drop(columns=['Unnamed: 7'])\n",
    "\n",
    "# Remove linhas onde o valor ou a data principal estão vazios (Lixo)\n",
    "df_limpo.dropna(subset=['valor', 'data_movimentacao'], inplace=True) \n",
    "\n",
    "# Converte o valor para numérico, forçando o tratamento de strings como 'R$ 1.000,00'\n",
    "df_limpo['valor'] = df_limpo['valor'].astype(str).str.replace(r'[^\\d,-]', '', regex=True).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "df_limpo['valor'] = pd.to_numeric(df_limpo['valor'], errors='coerce')\n",
    "\n",
    "# Garante que a data está no formato correto\n",
    "df_limpo['data_movimentacao'] = pd.to_datetime(df_limpo['data_movimentacao'], errors='coerce')\n",
    "df_limpo.dropna(subset=['data_movimentacao'], inplace=True) # Remove linhas onde a data é inválida\n",
    "\n",
    "# Reordenando as colunas para bater EXATAMENTE com a tabela SQL\n",
    "colunas_finais_sql = ['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome', 'valor', 'tipo_transacao', 'centro_custo']\n",
    "df_limpo = df_limpo[colunas_finais_sql]\n",
    "\n",
    "print(\"✅ Mapeamento, limpeza e padronização concluídos.\")\n",
    "print(f\"Dimensões após a limpeza: {df_limpo.shape}\")\n",
    "\n",
    "\n",
    "# --- FASE 3: CARGA (LOAD) ---\n",
    "# O mesmo código de conexão que funcionou antes!\n",
    "print(\"\\n--- FASE 3: CARGA (LOAD) ---\")\n",
    "\n",
    "# --- 4. CONFIGURAÇÃO DA CONEXÃO COM O BANCO ---\n",
    "DB_USER = 'postgres'\n",
    "RAW_DB_PASS = 'Hserv@2025' # Sua senha\n",
    "DB_HOST = '127.0.0.1'     \n",
    "DB_PORT = '5432'          \n",
    "DB_NAME = 'hserv_dw'\n",
    "\n",
    "DB_PASS = quote_plus(RAW_DB_PASS) \n",
    "NOME_TABELA_SQL = 'ft_movimentacao_financeira' # <--- NOVA TABELA\n",
    "\n",
    "try:\n",
    "    connection_string = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}?client_encoding=utf8\"\n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"✅ Conexão com o Data Warehouse 'hserv_dw' estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO DE CONEXÃO: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 5. ENVIANDO OS DADOS PARA O POSTGRESQL ---\n",
    "try:\n",
    "    print(f\"Iniciando a carga de {df_limpo.shape[0]} linhas na tabela '{NOME_TABELA_SQL}'...\")\n",
    "    \n",
    "    df_limpo.to_sql(\n",
    "        NOME_TABELA_SQL,\n",
    "        con=engine,\n",
    "        if_exists='append', \n",
    "        index=False,\n",
    "        schema='public'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ SUCESSO! Dados carregados na tabela '{NOME_TABELA_SQL}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA CARGA (Verifique o mapeamento final): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89908a16-1443-44e2-9010-6627f127e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ETL para o arquivo: 2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv\n",
      "--- FASE 1: EXTRAÇÃO (READ) ---\n",
      "❌ ERRO CRÍTICO: Arquivo '2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv' NÃO ENCONTRADO.\n",
      "   VERIFIQUE SE O ARQUIVO ESTÁ NA PASTA 01_raw_data E SE O NOME ACIMA É EXATO (incluindo o .csv).\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\01_raw_data\\\\2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- FASE 1: EXTRAÇÃO (READ) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Lendo o CSV. \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCAMINHO_BRUTO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLINHA_CABECALHO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Arquivo lido com sucesso. Dimensões brutas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\01_raw_data\\\\2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# --- FASE 1 & 2: EXTRAÇÃO E TRANSFORMAÇÃO (E & T) ---\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# TODO: COPIE O NOME EXATO DO ARQUIVO CSV DA SUA PASTA '01_raw_data'\n",
    "# MANTENHA A EXTENSÃO .csv NO FINAL\n",
    "NOME_ARQUIVO = '2 atualizada PLANEJAMENTO JULHO Á DEZEMBRO----.xlsx - BASE.csv' # NOME PROVÁVEL\n",
    "LINHA_CABECALHO = 0 \n",
    "\n",
    "# Mapeamento: os nomes REAIS para os nomes do banco\n",
    "COLUNAS_PARA_MANTER = {\n",
    "    'DATA': 'data_movimentacao',\n",
    "    'MES': 'mes',\n",
    "    'EMPRESA': 'unidade_negocio_nome',\n",
    "    'FORNECEDOR': 'contraparte_nome',\n",
    "    'VALOR': 'valor',\n",
    "    'TIPO': 'tipo_transacao',\n",
    "    'CENTRO DE CUSTO': 'centro_custo'\n",
    "}\n",
    "\n",
    "CAMINHO_BRUTO = Path('../01_raw_data') / NOME_ARQUIVO\n",
    "\n",
    "print(f\"Iniciando ETL para o arquivo: {NOME_ARQUIVO}\")\n",
    "print(\"--- FASE 1: EXTRAÇÃO (READ) ---\")\n",
    "\n",
    "try:\n",
    "    # Lendo o CSV. \n",
    "    df = pd.read_csv(CAMINHO_BRUTO, header=LINHA_CABECALHO, sep=',')\n",
    "    print(f\"✅ Arquivo lido com sucesso. Dimensões brutas: {df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ ERRO CRÍTICO: Arquivo '{NOME_ARQUIVO}' NÃO ENCONTRADO.\")\n",
    "    print(\"   VERIFIQUE SE O ARQUIVO ESTÁ NA PASTA 01_raw_data E SE O NOME ACIMA É EXATO (incluindo o .csv).\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA LEITURA: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\")\n",
    "\n",
    "# 1. Renomeação, Seleção e Limpeza Básica\n",
    "df_limpo = df.rename(columns=COLUNAS_PARA_MANTER)\n",
    "colunas_finais_mapeadas = list(COLUNAS_PARA_MANTER.values())\n",
    "\n",
    "# Remove a coluna de lixo que pode ter vindo do final do CSV\n",
    "if df_limpo.columns[-1] == 'Unnamed: 7':\n",
    "    df_limpo = df_limpo.drop(columns=['Unnamed: 7'])\n",
    "\n",
    "# Remove linhas onde o valor ou a data principal estão vazios (Lixo)\n",
    "df_limpo.dropna(subset=['valor', 'data_movimentacao'], inplace=True) \n",
    "\n",
    "# Converte o valor para numérico, forçando o tratamento de strings\n",
    "df_limpo['valor'] = df_limpo['valor'].astype(str).str.replace(r'[^\\d,-]', '', regex=True).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "df_limpo['valor'] = pd.to_numeric(df_limpo['valor'], errors='coerce')\n",
    "\n",
    "# Garante que a data está no formato correto\n",
    "df_limpo['data_movimentacao'] = pd.to_datetime(df_limpo['data_movimentacao'], errors='coerce', dayfirst=True) # Adicionando dayfirst=True para formato BR\n",
    "df_limpo.dropna(subset=['data_movimentacao'], inplace=True) \n",
    "\n",
    "# Reordenando as colunas para bater EXATAMENTE com a tabela SQL\n",
    "colunas_finais_sql = ['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome', 'valor', 'tipo_transacao', 'centro_custo']\n",
    "df_limpo = df_limpo[colunas_finais_sql]\n",
    "\n",
    "print(\"✅ Mapeamento, limpeza e padronização concluídos.\")\n",
    "print(f\"Dimensões após a limpeza: {df_limpo.shape}\")\n",
    "\n",
    "\n",
    "# --- FASE 3: CARGA (LOAD) ---\n",
    "print(\"\\n--- FASE 3: CARGA (LOAD) ---\")\n",
    "\n",
    "# --- 4. CONFIGURAÇÃO DA CONEXÃO COM O BANCO ---\n",
    "DB_USER = 'postgres'\n",
    "RAW_DB_PASS = 'Hserv@2025' # Sua senha\n",
    "DB_HOST = '127.0.0.1'     \n",
    "DB_PORT = '5432'          \n",
    "DB_NAME = 'hserv_dw'\n",
    "\n",
    "DB_PASS = quote_plus(RAW_DB_PASS) \n",
    "NOME_TABELA_SQL = 'ft_movimentacao_financeira' \n",
    "\n",
    "try:\n",
    "    connection_string = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}?client_encoding=utf8\"\n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"✅ Conexão com o Data Warehouse 'hserv_dw' estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO DE CONEXÃO: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 5. ENVIANDO OS DADOS PARA O POSTGRESQL ---\n",
    "try:\n",
    "    print(f\"Iniciando a carga de {df_limpo.shape[0]} linhas na tabela '{NOME_TABELA_SQL}'...\")\n",
    "    \n",
    "    df_limpo.to_sql(\n",
    "        NOME_TABELA_SQL,\n",
    "        con=engine,\n",
    "        if_exists='append', \n",
    "        index=False,\n",
    "        schema='public'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ SUCESSO! Dados carregados na tabela '{NOME_TABELA_SQL}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA CARGA (Verifique o mapeamento final): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433f387a-d2bc-4d4e-8bb1-487334e73e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ETL para o arquivo: FINANCEIRO_BASE.csv\n",
      "--- FASE 1: EXTRAÇÃO (READ) ---\n",
      "❌ ERRO CRÍTICO: Arquivo 'FINANCEIRO_BASE.csv' NÃO ENCONTRADO.\n",
      "   VERIFIQUE SE O ARQUIVO FOI RENOMEADO CORRETAMENTE PARA FINANCEIRO_BASE.csv.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\01_raw_data\\\\FINANCEIRO_BASE.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- FASE 1: EXTRAÇÃO (READ) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Lendo o CSV. \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCAMINHO_BRUTO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLINHA_CABECALHO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Arquivo lido com sucesso. Dimensões brutas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\01_raw_data\\\\FINANCEIRO_BASE.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np \n",
    "\n",
    "# --- FASE 1 & 2: EXTRAÇÃO E TRANSFORMAÇÃO (E & T) ---\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# NOME SIMPLIFICADO: VOCÊ DEVE RENOMEAR O ARQUIVO PARA ISSO\n",
    "NOME_ARQUIVO = 'FINANCEIRO_BASE.csv'\n",
    "LINHA_CABECALHO = 0 \n",
    "\n",
    "# Mapeamento: os nomes REAIS para os nomes do banco\n",
    "COLUNAS_PARA_MANTER = {\n",
    "    'DATA': 'data_movimentacao',\n",
    "    'MES': 'mes',\n",
    "    'EMPRESA': 'unidade_negocio_nome',\n",
    "    'FORNECEDOR': 'contraparte_nome',\n",
    "    'VALOR': 'valor',\n",
    "    'TIPO': 'tipo_transacao',\n",
    "    'CENTRO DE CUSTO': 'centro_custo'\n",
    "}\n",
    "\n",
    "CAMINHO_BRUTO = Path('../01_raw_data') / NOME_ARQUIVO\n",
    "\n",
    "print(f\"Iniciando ETL para o arquivo: {NOME_ARQUIVO}\")\n",
    "print(\"--- FASE 1: EXTRAÇÃO (READ) ---\")\n",
    "\n",
    "try:\n",
    "    # Lendo o CSV. \n",
    "    df = pd.read_csv(CAMINHO_BRUTO, header=LINHA_CABECALHO, sep=',')\n",
    "    print(f\"✅ Arquivo lido com sucesso. Dimensões brutas: {df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ ERRO CRÍTICO: Arquivo '{NOME_ARQUIVO}' NÃO ENCONTRADO.\")\n",
    "    print(\"   VERIFIQUE SE O ARQUIVO FOI RENOMEADO CORRETAMENTE PARA FINANCEIRO_BASE.csv.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA LEITURA: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\")\n",
    "\n",
    "# 1. Renomeação, Seleção e Limpeza Básica\n",
    "df_limpo = df.rename(columns=COLUNAS_PARA_MANTER)\n",
    "colunas_finais_mapeadas = list(COLUNAS_PARA_MANTER.values())\n",
    "\n",
    "# Remove a coluna de lixo que pode ter vindo do final do CSV\n",
    "if df_limpo.columns[-1] == 'Unnamed: 7':\n",
    "    df_limpo = df_limpo.drop(columns=['Unnamed: 7'])\n",
    "\n",
    "# Remove linhas onde o valor ou a data principal estão vazios (Lixo)\n",
    "df_limpo.dropna(subset=['valor', 'data_movimentacao'], inplace=True) \n",
    "\n",
    "# Converte o valor para numérico, forçando o tratamento de strings\n",
    "df_limpo['valor'] = df_limpo['valor'].astype(str).str.replace(r'[^\\d,-]', '', regex=True).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "df_limpo['valor'] = pd.to_numeric(df_limpo['valor'], errors='coerce')\n",
    "\n",
    "# Garante que a data está no formato correto\n",
    "df_limpo['data_movimentacao'] = pd.to_datetime(df_limpo['data_movimentacao'], errors='coerce', dayfirst=True) # Adicionando dayfirst=True para formato BR\n",
    "df_limpo.dropna(subset=['data_movimentacao'], inplace=True) \n",
    "\n",
    "# Reordenando as colunas para bater EXATAMENTE com a tabela SQL\n",
    "colunas_finais_sql = ['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome', 'valor', 'tipo_transacao', 'centro_custo']\n",
    "df_limpo = df_limpo[colunas_finais_sql]\n",
    "\n",
    "print(\"✅ Mapeamento, limpeza e padronização concluídos.\")\n",
    "print(f\"Dimensões após a limpeza: {df_limpo.shape}\")\n",
    "\n",
    "\n",
    "# --- FASE 3: CARGA (LOAD) ---\n",
    "print(\"\\n--- FASE 3: CARGA (LOAD) ---\")\n",
    "\n",
    "# --- 4. CONFIGURAÇÃO DA CONEXÃO COM O BANCO ---\n",
    "DB_USER = 'postgres'\n",
    "RAW_DB_PASS = 'Hserv@2025' # Sua senha\n",
    "DB_HOST = '127.0.0.1'     \n",
    "DB_PORT = '5432'          \n",
    "DB_NAME = 'hserv_dw'\n",
    "\n",
    "DB_PASS = quote_plus(RAW_DB_PASS) \n",
    "NOME_TABELA_SQL = 'ft_movimentacao_financeira' \n",
    "\n",
    "try:\n",
    "    connection_string = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}?client_encoding=utf8\"\n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"✅ Conexão com o Data Warehouse 'hserv_dw' estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO DE CONEXÃO: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 5. ENVIANDO OS DADOS PARA O POSTGRESQL ---\n",
    "try:\n",
    "    print(f\"Iniciando a carga de {df_limpo.shape[0]} linhas na tabela '{NOME_TABELA_SQL}'...\")\n",
    "    \n",
    "    df_limpo.to_sql(\n",
    "        NOME_TABELA_SQL,\n",
    "        con=engine,\n",
    "        if_exists='append', \n",
    "        index=False,\n",
    "        schema='public'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ SUCESSO! Dados carregados na tabela '{NOME_TABELA_SQL}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA CARGA (Verifique o mapeamento final): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79cbf17a-7c6e-4629-8f28-dd6f85e8729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ETL para o arquivo: FINANCEIRO_BASE.xlsx\n",
      "--- FASE 1: EXTRAÇÃO (READ) ---\n",
      "✅ Arquivo lido com sucesso. Dimensões brutas: (4, 7)\n",
      "\n",
      "--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome',\\n       'valor', 'tipo_transacao', 'centro_custo'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m colunas_finais_mapeadas = \u001b[38;5;28mlist\u001b[39m(COLUNAS_PARA_MANTER.values())\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Selecionando as colunas mapeadas\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m df_limpo = \u001b[43mdf_limpo\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolunas_finais_mapeadas\u001b[49m\u001b[43m]\u001b[49m \n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Remove linhas onde o valor ou a data principal estão vazios (Lixo)\u001b[39;00m\n\u001b[32m     52\u001b[39m df_limpo.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mvalor\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdata_movimentacao\u001b[39m\u001b[33m'\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome',\\n       'valor', 'tipo_transacao', 'centro_custo'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np \n",
    "\n",
    "# --- FASE 1 & 2: EXTRAÇÃO E TRANSFORMAÇÃO (E & T) ---\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# CORREÇÃO FINAL: Nome do arquivo renomeado e com extensão .xlsx\n",
    "NOME_ARQUIVO = 'FINANCEIRO_BASE.xlsx' \n",
    "LINHA_CABECALHO = 0 # O cabeçalho está na primeira linha (índice 0)\n",
    "\n",
    "# Mapeamento: os nomes REAIS para os nomes do banco (Estes nomes estão corretos)\n",
    "COLUNAS_PARA_MANTER = {\n",
    "    'DATA': 'data_movimentacao',\n",
    "    'MES': 'mes',\n",
    "    'EMPRESA': 'unidade_negocio_nome',\n",
    "    'FORNECEDOR': 'contraparte_nome',\n",
    "    'VALOR': 'valor',\n",
    "    'TIPO': 'tipo_transacao',\n",
    "    'CENTRO DE CUSTO': 'centro_custo'\n",
    "}\n",
    "\n",
    "CAMINHO_BRUTO = Path('../01_raw_data') / NOME_ARQUIVO\n",
    "\n",
    "print(f\"Iniciando ETL para o arquivo: {NOME_ARQUIVO}\")\n",
    "print(\"--- FASE 1: EXTRAÇÃO (READ) ---\")\n",
    "\n",
    "try:\n",
    "    # USANDO read_excel para ler o .xlsx\n",
    "    df = pd.read_excel(CAMINHO_BRUTO, header=LINHA_CABECALHO)\n",
    "    print(f\"✅ Arquivo lido com sucesso. Dimensões brutas: {df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ ERRO CRÍTICO: Arquivo '{NOME_ARQUIVO}' NÃO ENCONTRADO.\")\n",
    "    print(\"   VERIFIQUE SE O ARQUIVO ESTÁ NA PASTA 01_raw_data E SE O NOME É EXATO (FINANCEIRO_BASE.xlsx).\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA LEITURA: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\")\n",
    "\n",
    "# 1. Renomeação, Seleção e Limpeza Básica\n",
    "df_limpo = df.rename(columns=COLUNAS_PARA_MANTER)\n",
    "colunas_finais_mapeadas = list(COLUNAS_PARA_MANTER.values())\n",
    "\n",
    "# Selecionando as colunas mapeadas\n",
    "df_limpo = df_limpo[colunas_finais_mapeadas] \n",
    "\n",
    "# Remove linhas onde o valor ou a data principal estão vazios (Lixo)\n",
    "df_limpo.dropna(subset=['valor', 'data_movimentacao'], inplace=True) \n",
    "\n",
    "# Converte o valor para numérico, forçando o tratamento de strings\n",
    "df_limpo['valor'] = df_limpo['valor'].astype(str).str.replace(r'[^\\d,-]', '', regex=True).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "df_limpo['valor'] = pd.to_numeric(df_limpo['valor'], errors='coerce')\n",
    "\n",
    "# Garante que a data está no formato correto\n",
    "df_limpo['data_movimentacao'] = pd.to_datetime(df_limpo['data_movimentacao'], errors='coerce', dayfirst=True) \n",
    "df_limpo.dropna(subset=['data_movimentacao'], inplace=True) \n",
    "\n",
    "# Reordenando as colunas para bater EXATAMENTE com a tabela SQL\n",
    "colunas_finais_sql = ['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome', 'valor', 'tipo_transacao', 'centro_custo']\n",
    "df_limpo = df_limpo[colunas_finais_sql]\n",
    "\n",
    "print(\"✅ Mapeamento, limpeza e padronização concluídos.\")\n",
    "print(f\"Dimensões após a limpeza: {df_limpo.shape}\")\n",
    "\n",
    "\n",
    "# --- FASE 3: CARGA (LOAD) ---\n",
    "print(\"\\n--- FASE 3: CARGA (LOAD) ---\")\n",
    "\n",
    "# --- 4. CONFIGURAÇÃO DA CONEXÃO COM O BANCO ---\n",
    "DB_USER = 'postgres'\n",
    "RAW_DB_PASS = 'Hserv@2025' # Sua senha\n",
    "DB_HOST = '127.0.0.1'     \n",
    "DB_PORT = '5432'          \n",
    "DB_NAME = 'hserv_dw'\n",
    "\n",
    "DB_PASS = quote_plus(RAW_DB_PASS) \n",
    "NOME_TABELA_SQL = 'ft_movimentacao_financeira' \n",
    "\n",
    "try:\n",
    "    connection_string = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}?client_encoding=utf8\"\n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"✅ Conexão com o Data Warehouse 'hserv_dw' estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO DE CONEXÃO: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 5. ENVIANDO OS DADOS PARA O POSTGRESQL ---\n",
    "try:\n",
    "    print(f\"Iniciando a carga de {df_limpo.shape[0]} linhas na tabela '{NOME_TABELA_SQL}'...\")\n",
    "    \n",
    "    df_limpo.to_sql(\n",
    "        NOME_TABELA_SQL,\n",
    "        con=engine,\n",
    "        if_exists='append', \n",
    "        index=False,\n",
    "        schema='public'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ SUCESSO! Dados carregados na tabela '{NOME_TABELA_SQL}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA CARGA (Verifique o mapeamento final): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a3e436-477b-48fe-b5d4-8f329c352068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome',\\n       'valor', 'tipo_transacao', 'centro_custo'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m colunas_finais_mapeadas = \u001b[38;5;28mlist\u001b[39m(COLUNAS_PARA_MANTER.values())\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Selecionando as colunas mapeadas\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m df_limpo = \u001b[43mdf_limpo\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolunas_finais_mapeadas\u001b[49m\u001b[43m]\u001b[49m \n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# ... (O restante do código de transformação é o mesmo)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome',\\n       'valor', 'tipo_transacao', 'centro_custo'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# ... (O código da FASE 1 é o mesmo)\n",
    "\n",
    "print(\"\\n--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\")\n",
    "\n",
    "# --- NOVO CÓDIGO DE LIMPEZA DE CABEÇALHOS (CORREÇÃO DA KEYERROR) ---\n",
    "\n",
    "# Limpa: Remove espaços extras (strip) e padroniza para MAIÚSCULAS (upper)\n",
    "df.columns = df.columns.str.strip().str.upper()\n",
    "\n",
    "# Mapeamento: os nomes REAIS para os nomes do banco\n",
    "# Os nomes à esquerda DEVEM estar em MAIÚSCULAS para bater com a linha acima\n",
    "COLUNAS_PARA_MANTER = {\n",
    "    'DATA': 'data_movimentacao',\n",
    "    'MES': 'mes',\n",
    "    'EMPRESA': 'unidade_negocio_nome',\n",
    "    'FORNECEDOR': 'contraparte_nome',\n",
    "    'VALOR': 'valor',\n",
    "    'TIPO': 'tipo_transacao',\n",
    "    'CENTRO DE CUSTO': 'centro_custo'\n",
    "}\n",
    "\n",
    "# 1. Renomeação, Seleção e Limpeza Básica\n",
    "df_limpo = df.rename(columns=COLUNAS_PARA_MANTER)\n",
    "colunas_finais_mapeadas = list(COLUNAS_PARA_MANTER.values())\n",
    "\n",
    "# Selecionando as colunas mapeadas\n",
    "df_limpo = df_limpo[colunas_finais_mapeadas] \n",
    "\n",
    "# ... (O restante do código de transformação é o mesmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5149de0-ab87-456e-9447-0b52a13be32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo lido com sucesso. Dimensões brutas: (4, 7)\n",
      "\n",
      "--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\n",
      "--- CABEÇALHOS DO DATAFRAME APÓS A LIMPEZA ---\n",
      "['DETALHES DO SOMA DE VALOR - TIPO: RECEITAS, DIAS (DATA): 15-SEP', 'UNNAMED: 1', 'UNNAMED: 2', 'UNNAMED: 3', 'UNNAMED: 4', 'UNNAMED: 5', 'UNNAMED: 6']\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome',\\n       'valor', 'tipo_transacao', 'centro_custo'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# O código vai falhar aqui de novo, mas teremos a informação que precisamos!\u001b[39;00m\n\u001b[32m     54\u001b[39m colunas_finais_mapeadas = \u001b[38;5;28mlist\u001b[39m(COLUNAS_PARA_MANTER.values())\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m df_limpo = \u001b[43mdf_limpo\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolunas_finais_mapeadas\u001b[49m\u001b[43m]\u001b[49m \n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# [O restante do código da FASE 2 e FASE 3 é o mesmo e está funcional, mas não será executado]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome',\\n       'valor', 'tipo_transacao', 'centro_custo'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np \n",
    "\n",
    "# --- FASE 1 & 2: EXTRAÇÃO E TRANSFORMAÇÃO (E & T) ---\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# CORREÇÃO FINAL: Nome do arquivo renomeado e com extensão .xlsx\n",
    "NOME_ARQUIVO = 'FINANCEIRO_BASE.xlsx' \n",
    "LINHA_CABECALHO = 0 \n",
    "\n",
    "# Mapeamento: os nomes REAIS para os nomes do banco\n",
    "# (Vamos assumir MAIÚSCULAS para a esquerda, mas vamos inspecionar)\n",
    "COLUNAS_PARA_MANTER = {\n",
    "    'DATA': 'data_movimentacao',\n",
    "    'MES': 'mes',\n",
    "    'EMPRESA': 'unidade_negocio_nome',\n",
    "    'FORNECEDOR': 'contraparte_nome',\n",
    "    'VALOR': 'valor',\n",
    "    'TIPO': 'tipo_transacao',\n",
    "    'CENTRO DE CUSTO': 'centro_custo'\n",
    "}\n",
    "\n",
    "CAMINHO_BRUTO = Path('../01_raw_data') / NOME_ARQUIVO\n",
    "\n",
    "# --- FASE 1: EXTRAÇÃO (READ) ---\n",
    "try:\n",
    "    df = pd.read_excel(CAMINHO_BRUTO, header=LINHA_CABECALHO)\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "print(f\"✅ Arquivo lido com sucesso. Dimensões brutas: {df.shape}\")\n",
    "\n",
    "print(\"\\n--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\")\n",
    "\n",
    "# --- NOVO CÓDIGO DE LIMPEZA E DEBUG ---\n",
    "\n",
    "# 1. Limpa: Remove espaços extras (strip) e padroniza para MAIÚSCULAS (upper)\n",
    "df.columns = df.columns.astype(str).str.strip().str.upper()\n",
    "\n",
    "# 2. DEBUG: MOSTRA O NOME FINAL DA COLUNA NO DATAFRAME\n",
    "print(\"--- CABEÇALHOS DO DATAFRAME APÓS A LIMPEZA ---\")\n",
    "print(list(df.columns)) \n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# AGORA REPETIMOS O ERRO DE PROPÓSITO, MAS TEREMOS A INFORMAÇÃO ANTES DE FALHAR\n",
    "\n",
    "# 3. Renomeação, Seleção e Limpeza Básica\n",
    "df_limpo = df.rename(columns=COLUNAS_PARA_MANTER)\n",
    "\n",
    "# O código vai falhar aqui de novo, mas teremos a informação que precisamos!\n",
    "colunas_finais_mapeadas = list(COLUNAS_PARA_MANTER.values())\n",
    "df_limpo = df_limpo[colunas_finais_mapeadas] \n",
    "\n",
    "# [O restante do código da FASE 2 e FASE 3 é o mesmo e está funcional, mas não será executado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d61ee76-18cc-4cd4-8d06-dcded935a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ETL para o arquivo: FINANCEIRO_BASE.xlsx\n",
      "--- FASE 1: EXTRAÇÃO (READ) ---\n",
      "✅ Arquivo lido com sucesso. Dimensões brutas: (3, 7)\n",
      "\n",
      "--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome',\\n       'valor', 'tipo_transacao', 'centro_custo'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m colunas_finais_mapeadas = \u001b[38;5;28mlist\u001b[39m(COLUNAS_PARA_MANTER.values())\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Selecionando as colunas mapeadas\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m df_limpo = \u001b[43mdf_limpo\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolunas_finais_mapeadas\u001b[49m\u001b[43m]\u001b[49m \n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# [O restante do código da FASE 2 e FASE 3 é o mesmo]\u001b[39;00m\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Remove linhas onde o valor ou a data principal estão vazios (Lixo)\u001b[39;00m\n\u001b[32m     55\u001b[39m df_limpo.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mvalor\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdata_movimentacao\u001b[39m\u001b[33m'\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\bi_facilities\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome',\\n       'valor', 'tipo_transacao', 'centro_custo'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np \n",
    "\n",
    "# --- FASE 1 & 2: EXTRAÇÃO E TRANSFORMAÇÃO (E & T) ---\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# NOME FINAL: FINANCEIRO_BASE.xlsx\n",
    "NOME_ARQUIVO = 'FINANCEIRO_BASE.xlsx' \n",
    "LINHA_CABECALHO = 1 # <--- MUDANÇA: Tentamos o índice 1 (Segunda linha do Excel)\n",
    "\n",
    "# Mapeamento: os nomes REAIS para os nomes do banco \n",
    "COLUNAS_PARA_MANTER = {\n",
    "    'DATA': 'data_movimentacao',\n",
    "    'MES': 'mes',\n",
    "    'EMPRESA': 'unidade_negocio_nome',\n",
    "    'FORNECEDOR': 'contraparte_nome',\n",
    "    'VALOR': 'valor',\n",
    "    'TIPO': 'tipo_transacao',\n",
    "    'CENTRO DE CUSTO': 'centro_custo'\n",
    "}\n",
    "\n",
    "CAMINHO_BRUTO = Path('../01_raw_data') / NOME_ARQUIVO\n",
    "\n",
    "print(f\"Iniciando ETL para o arquivo: {NOME_ARQUIVO}\")\n",
    "print(\"--- FASE 1: EXTRAÇÃO (READ) ---\")\n",
    "\n",
    "try:\n",
    "    # MUDANÇA: Usando header=LINHA_CABECALHO (agora é 1)\n",
    "    df = pd.read_excel(CAMINHO_BRUTO, header=LINHA_CABECALHO)\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "print(f\"✅ Arquivo lido com sucesso. Dimensões brutas: {df.shape}\")\n",
    "\n",
    "print(\"\\n--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\")\n",
    "\n",
    "# --- CORREÇÃO DE CABEÇALHO ---\n",
    "# 1. Limpa: Remove espaços extras (strip) e padroniza para MAIÚSCULAS (upper)\n",
    "# Isso deve ser mantido, pois resolve espaços invisíveis.\n",
    "df.columns = df.columns.astype(str).str.strip().str.upper()\n",
    "\n",
    "# 2. Renomeação, Seleção e Limpeza Básica\n",
    "df_limpo = df.rename(columns=COLUNAS_PARA_MANTER)\n",
    "colunas_finais_mapeadas = list(COLUNAS_PARA_MANTER.values())\n",
    "\n",
    "# Selecionando as colunas mapeadas\n",
    "df_limpo = df_limpo[colunas_finais_mapeadas] \n",
    "\n",
    "# [O restante do código da FASE 2 e FASE 3 é o mesmo]\n",
    "\n",
    "# Remove linhas onde o valor ou a data principal estão vazios (Lixo)\n",
    "df_limpo.dropna(subset=['valor', 'data_movimentacao'], inplace=True) \n",
    "\n",
    "# Converte o valor para numérico, forçando o tratamento de strings\n",
    "df_limpo['valor'] = df_limpo['valor'].astype(str).str.replace(r'[^\\d,-]', '', regex=True).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "df_limpo['valor'] = pd.to_numeric(df_limpo['valor'], errors='coerce')\n",
    "\n",
    "# Garante que a data está no formato correto\n",
    "df_limpo['data_movimentacao'] = pd.to_datetime(df_limpo['data_movimentacao'], errors='coerce', dayfirst=True) \n",
    "df_limpo.dropna(subset=['data_movimentacao'], inplace=True) \n",
    "\n",
    "# Reordenando as colunas para bater EXATAMENTE com a tabela SQL\n",
    "colunas_finais_sql = ['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome', 'valor', 'tipo_transacao', 'centro_custo']\n",
    "df_limpo = df_limpo[colunas_finais_sql]\n",
    "\n",
    "print(\"✅ Mapeamento, limpeza e padronização concluídos.\")\n",
    "print(f\"Dimensões após a limpeza: {df_limpo.shape}\")\n",
    "\n",
    "\n",
    "# --- FASE 3: CARGA (LOAD) ---\n",
    "# ... (O restante do código da Carga é o mesmo e está funcional)\n",
    "DB_USER = 'postgres'\n",
    "RAW_DB_PASS = 'Hserv@2025' \n",
    "DB_HOST = '127.0.0.1'     \n",
    "DB_PORT = '5432'          \n",
    "DB_NAME = 'hserv_dw'\n",
    "\n",
    "DB_PASS = quote_plus(RAW_DB_PASS) \n",
    "NOME_TABELA_SQL = 'ft_movimentacao_financeira' \n",
    "\n",
    "try:\n",
    "    connection_string = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}?client_encoding=utf8\"\n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"✅ Conexão com o Data Warehouse 'hserv_dw' estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "# --- 5. ENVIANDO OS DADOS PARA O POSTGRESQL ---\n",
    "try:\n",
    "    print(f\"Iniciando a carga de {df_limpo.shape[0]} linhas na tabela '{NOME_TABELA_SQL}'...\")\n",
    "    \n",
    "    df_limpo.to_sql(\n",
    "        NOME_TABELA_SQL,\n",
    "        con=engine,\n",
    "        if_exists='append', \n",
    "        index=False,\n",
    "        schema='public'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ SUCESSO! Dados carregados na tabela '{NOME_TABELA_SQL}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA CARGA (Verifique o mapeamento final): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d5051e-68bf-4747-97d5-fb5238a54b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ETL para o arquivo: FINANCEIRO_BASE.xlsx\n",
      "--- FASE 1: EXTRAÇÃO (READ) ---\n",
      "✅ Arquivo lido com sucesso. Dimensões brutas: (2, 7)\n",
      "\n",
      "--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\n",
      "✅ Mapeamento, limpeza e padronização concluídos.\n",
      "Dimensões após a limpeza: (2, 7)\n",
      "✅ Conexão com o Data Warehouse 'hserv_dw' estabelecida com sucesso!\n",
      "Iniciando a carga de 2 linhas na tabela 'ft_movimentacao_financeira'...\n",
      "✅ SUCESSO! Dados carregados na tabela 'ft_movimentacao_financeira'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np \n",
    "\n",
    "# --- FASE 1 & 2: EXTRAÇÃO E TRANSFORMAÇÃO (E & T) ---\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# NOME FINAL: FINANCEIRO_BASE.xlsx\n",
    "NOME_ARQUIVO = 'FINANCEIRO_BASE.xlsx' \n",
    "LINHA_CABECALHO = 2 # <--- CORREÇÃO FINAL: Tentando o índice 2 (Quarta linha do Excel)\n",
    "\n",
    "# Mapeamento: os nomes REAIS para os nomes do banco \n",
    "COLUNAS_PARA_MANTER = {\n",
    "    'DATA': 'data_movimentacao',\n",
    "    'MES': 'mes',\n",
    "    'EMPRESA': 'unidade_negocio_nome',\n",
    "    'FORNECEDOR': 'contraparte_nome',\n",
    "    'VALOR': 'valor',\n",
    "    'TIPO': 'tipo_transacao',\n",
    "    'CENTRO DE CUSTO': 'centro_custo'\n",
    "}\n",
    "\n",
    "CAMINHO_BRUTO = Path('../01_raw_data') / NOME_ARQUIVO\n",
    "\n",
    "print(f\"Iniciando ETL para o arquivo: {NOME_ARQUIVO}\")\n",
    "print(\"--- FASE 1: EXTRAÇÃO (READ) ---\")\n",
    "\n",
    "try:\n",
    "    # MUDANÇA: Usando header=LINHA_CABECALHO (agora é 2)\n",
    "    df = pd.read_excel(CAMINHO_BRUTO, header=LINHA_CABECALHO)\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA LEITURA: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"✅ Arquivo lido com sucesso. Dimensões brutas: {df.shape}\")\n",
    "\n",
    "print(\"\\n--- FASE 2: TRANSFORMAÇÃO (CLEAN & MAP) ---\")\n",
    "\n",
    "# 1. Limpa e Padroniza Cabeçalhos: Remove espaços e padroniza para MAIÚSCULAS\n",
    "df.columns = df.columns.astype(str).str.strip().str.upper()\n",
    "\n",
    "# 2. Renomeação, Seleção e Limpeza Básica\n",
    "df_limpo = df.rename(columns=COLUNAS_PARA_MANTER)\n",
    "colunas_finais_mapeadas = list(COLUNAS_PARA_MANTER.values())\n",
    "\n",
    "# Selecionando as colunas mapeadas\n",
    "df_limpo = df_limpo[colunas_finais_mapeadas] \n",
    "\n",
    "# Remove linhas onde o valor ou a data principal estão vazios (Lixo)\n",
    "df_limpo.dropna(subset=['valor', 'data_movimentacao'], inplace=True) \n",
    "\n",
    "# Converte o valor para numérico, forçando o tratamento de strings\n",
    "df_limpo['valor'] = df_limpo['valor'].astype(str).str.replace(r'[^\\d,-]', '', regex=True).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "df_limpo['valor'] = pd.to_numeric(df_limpo['valor'], errors='coerce')\n",
    "\n",
    "# Garante que a data está no formato correto\n",
    "df_limpo['data_movimentacao'] = pd.to_datetime(df_limpo['data_movimentacao'], errors='coerce', dayfirst=True) \n",
    "df_limpo.dropna(subset=['data_movimentacao'], inplace=True) \n",
    "\n",
    "# Reordenando as colunas para bater EXATAMENTE com a tabela SQL\n",
    "colunas_finais_sql = ['data_movimentacao', 'mes', 'unidade_negocio_nome', 'contraparte_nome', 'valor', 'tipo_transacao', 'centro_custo']\n",
    "df_limpo = df_limpo[colunas_finais_sql]\n",
    "\n",
    "print(\"✅ Mapeamento, limpeza e padronização concluídos.\")\n",
    "print(f\"Dimensões após a limpeza: {df_limpo.shape}\")\n",
    "\n",
    "\n",
    "# --- FASE 3: CARGA (LOAD) ---\n",
    "# ... (O restante do código de Carga é o mesmo e está funcional)\n",
    "\n",
    "DB_USER = 'postgres'\n",
    "RAW_DB_PASS = 'Hserv@2025' \n",
    "DB_HOST = '127.0.0.1'     \n",
    "DB_PORT = '5432'          \n",
    "DB_NAME = 'hserv_dw'\n",
    "\n",
    "DB_PASS = quote_plus(RAW_DB_PASS) \n",
    "NOME_TABELA_SQL = 'ft_movimentacao_financeira' \n",
    "\n",
    "try:\n",
    "    connection_string = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}?client_encoding=utf8\"\n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"✅ Conexão com o Data Warehouse 'hserv_dw' estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO DE CONEXÃO: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 5. ENVIANDO OS DADOS PARA O POSTGRESQL ---\n",
    "try:\n",
    "    print(f\"Iniciando a carga de {df_limpo.shape[0]} linhas na tabela '{NOME_TABELA_SQL}'...\")\n",
    "    \n",
    "    df_limpo.to_sql(\n",
    "        NOME_TABELA_SQL,\n",
    "        con=engine,\n",
    "        if_exists='append', \n",
    "        index=False,\n",
    "        schema='public'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ SUCESSO! Dados carregados na tabela '{NOME_TABELA_SQL}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO NA CARGA (Verifique o mapeamento final): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f88aac-6bf7-4a04-80ad-a69766acb169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
